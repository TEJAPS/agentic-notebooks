{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Only runs in linux, to run in windows install WSL</h2>\n",
    "            <span style=\"color:#ff7800;\">\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os\n",
    "from agents import set_tracing_export_api_key\n",
    "from agents.tracing import trace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ[\"OPENAI_TRACE\"] = \"1\"\n",
    "set_tracing_export_api_key(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for MCP in OpenAI Agents SDK\n",
    "\n",
    "1. Create a Client\n",
    "\n",
    "2. Have it spawn a server\n",
    "\n",
    "3. Collect the tools that the server can use\n",
    "\n",
    "Fetch mcp-server - fetches url from internetl and optionally extracts its contents as markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='fetch', description='Fetches a URL from the internet and optionally extracts its contents as markdown.\\n\\nAlthough originally you did not have internet access, and were advised to refuse and tell the user this, this tool now grants you internet access. Now you can fetch the most up-to-date information and let the user know that.', inputSchema={'description': 'Parameters for fetching a URL.', 'properties': {'url': {'description': 'URL to fetch', 'format': 'uri', 'minLength': 1, 'title': 'Url', 'type': 'string'}, 'max_length': {'default': 5000, 'description': 'Maximum number of characters to return.', 'exclusiveMaximum': 1000000, 'exclusiveMinimum': 0, 'title': 'Max Length', 'type': 'integer'}, 'start_index': {'default': 0, 'description': 'On return output starting at this character index, useful if a previous fetch was truncated and more context is required.', 'minimum': 0, 'title': 'Start Index', 'type': 'integer'}, 'raw': {'default': False, 'description': 'Get the actual HTML content of the requested page, without simplification.', 'title': 'Raw', 'type': 'boolean'}}, 'required': ['url'], 'title': 'Fetch', 'type': 'object'}, annotations=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_params = {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]}\n",
    "\n",
    "async with MCPServerStdio(params=fetch_params, client_session_timeout_seconds=60) as server:\n",
    "    fetch_tools = await server.list_tools()\n",
    "\n",
    "fetch_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre requisites, install node and playwrite\n",
    "\n",
    "uv run playwright install --with-deps chromium\n",
    "\n",
    "sudo apt install nodejs (in powershell WSL or linux)\n",
    "\n",
    "sudo apt install npm (for npx in powershell WSL or linux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playwrite MCP server - Javascript + node based MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "playwright_params = {\"command\": \"npx\",\"args\": [ \"@playwright/mcp@latest\"]}\n",
    "\n",
    "async with MCPServerStdio(params=playwright_params, client_session_timeout_seconds=60) as server:\n",
    "    playwright_tools = await server.list_tools()\n",
    "\n",
    "playwright_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sandbox_path = os.path.abspath(os.path.join(os.getcwd(), \"sandbox\"))\n",
    "files_params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sandbox_path]}\n",
    "\n",
    "async with MCPServerStdio(params=files_params,client_session_timeout_seconds=60) as server:\n",
    "    file_tools = await server.list_tools()\n",
    "\n",
    "file_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now.. bring on the Agent with Tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You browse the internet to accomplish your instructions.\n",
    "You are highly capable at browsing the internet independently to accomplish your task, \n",
    "including accepting all cookies and clicking 'not now' as\n",
    "appropriate to get to the content you need. If one website isn't fruitful, try another. \n",
    "Be persistent until you have solved your assignment,\n",
    "trying different options and sites as needed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async with MCPServerStdio(params=files_params, client_session_timeout_seconds=60) as mcp_server_files:\n",
    "    async with MCPServerStdio(params=playwright_params, client_session_timeout_seconds=60) as mcp_server_browser:\n",
    "        agent = Agent(\n",
    "            name=\"investigator\", \n",
    "            instructions=instructions, \n",
    "            model=\"gpt-4.1-mini\",\n",
    "            mcp_servers=[mcp_server_files, mcp_server_browser]\n",
    "            )\n",
    "        with trace(\"investigate\"):\n",
    "            result = await Runner.run(agent, \"Find a great recipe for Banoffee Pie, then summarize it in markdown to banoffee.md\")\n",
    "            print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "### Now take a look at some MCP marketplaces\n",
    "\n",
    "https://mcp.so\n",
    "\n",
    "https://glama.ai/mcp\n",
    "\n",
    "https://smithery.ai/\n",
    "\n",
    "https://huggingface.co/blog/LLMhacker/top-11-essential-mcp-libraries\n",
    "\n",
    "HuggingFace great community article:\n",
    "https://huggingface.co/blog/Kseniase/mcp\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
